#add bias to input vector X
X <- cbind(1, X)
X
?colname
?colnames
colnames(X) <- c("theta0", "Population")
X
names(X)
colnames(X)
X
names(X) <- 1:nrow(X)
X
nrow(X)
#retrieve predictor and target variable values
X <- as.matrix(data1[, 1])
y <- as.matrix(data1[, 2])
#plot the data of input and output variables
plot(X[,1], y[,1], 'p', xlab="Population", ylab="Profit")
#add bias to input vector X
X <- cbind(1, X)
#set names of X and y
colnames(X) <- c("theta0", "Population")
colnames(y) <- c("Profit")
X
names(X)
nrow(X)
?names
?rownames
rownames(X) <- 1:nrow(X)
X
#set row names of X and y
rownames(X) <- 1:nrow(X)
rownames(y) <- 1:nrow(y)
X\
X
y
theta = matrix(data= 0, nrow = nrow(X), ncol = ncol(X))
theta
X
X %*% theta
ncol(X)
ncol(theta)
a=1:4
b=5:9
a%*% b
dim(X)
dim(theta)
X %*% t(theta)
X
theta
?function
()
theta = matrix(data= 0, nrow = nrow(X), ncol = 1)
X
X %*% theta
dim(X)
dim(theta)
theta = matrix(data= 0, nrow = ncol(X), ncol = 1)
X
dim(X)
dim(theta)
X %*% theta
length(X)
nrow(X)
X
96*2
m <- nrow(X)
htheta - y
htheta
theta = matrix(data= 0, nrow = ncol(X), ncol = 1)
htheta <- X %*% theta
htheta
theta
htheta
htheta - y
y
identical(htheta, y)
htheta
head(htheta)
merge(htheta, y)
nrow(y)
nrow(htheta)
cbind(htheta, y)
(htheta - y)^2
head((htheta - y)^2)
head(htheta - y)
?sum
#function to get the actual cost of the slr initially
costfunction_slr <- function(X, y, theta){
#initialise cost to zero value
J = 0
#find the hypothesis
htheta <- X %*% theta
#calculate squared error
sq_error <- (htheta - y)^2
J = J + sum(sq_error)
}
costvalue <- costfunction_slr(X, y , theta)
costvalue
y
?plot
library("ggplot2")
?version
R.version()
R.Version()
?GeomDotplot
example(geom_dotplot)
ggplot(mtcars)
ggplot(mtcars, aes(x))
x <- seq(-1, 2, 0.5)
sx
x
y1 <- pnorm(x)
y2 <- pnorm(x, 1, 1)
y1
y2
df <- data.frame(x, y1, y2)
df
ggplot(df, aes(x))
as.data.frame(X, y)
class(X)
class(u)
class(y)
X
rownames(X) <- as.integer(c(1:nrow(X)))
rownames(u) <- as.integer(c(1:nrow(y)))
rownames(y) <- as.integer(c(1:nrow(y)))
as.data.frame(X, y)
X
class(rownames(X))
data.frame(X, y)
as.data.frame(1,2)
g <- ggplot(data.frame(X, y), aes(X) )
g
g <- ggplot(data.frame(X, y), aes(X[,1]))
g
X[,1]
X
g <- ggplot(data.frame(X, y), aes(X[,2]) )
g
plot(X, y, 'p')
plot(X[,2], y[,1], 'p')
par(new=TRUE)
htheta
plot(y[,1], htheta, 'l')
plot(X[,1], y[,1], 'p', xlab="Population", ylab="Profit")
plot(X[,2], y[,1], 'p', xlab="Population", ylab="Profit")
par(new=TRUE)
plot(y[,1], htheta, 'l')
plot(y[,1], htheta, 'l', xlab="", ylab="")
plot(X[,2], y[,1], 'p', xlab="Population", ylab="Profit")
plot(y[,1], htheta, 'l', xlab="Population", ylab="Profit")
plot(X[,2], y[,1], 'p', xlab="Population", ylab="Profit")
par(new=TRUE)
plot(y[,1], htheta, 'l', xlab="Population", ylab="Profit")
dim(theta)
matrix(dim(theta))
matrix(dim(theta), data=0)
grad <- matrix(nrow=nrow(X), ncol=nrow(theta), data=0)
grad
a<-c(1,2,3,4,5)
grad_temp <- rep(1, times=ncol(grad))
grad_temp
a
a[1]
a[2]
J_val <- matrix(nrow=iterations, ncol=1, data=0)
J_val
#function to calculate gradients
calculateGradients_slr <- function(X, y, theta, alpha, iterations){
#initialize the gradient matrix
J_val <- matrix(nrow=iterations, ncol=1, data=0)
for (iter in iterations){
htheta <- X %*% theta
error <- (htheta - y)
grad_temp <- rep(0, times=ncol(grad))
for (j in ncol(theta)){
grad_temp[j] <- grad[, j] - (alpha/m) %*% ((error) %*% X[, j])
}
#after calculating current gradient descent for all the parameters
theta <- grad_temp
#get the cost using current theta parameter
J[iter,] <- costfunction_slr(X, y, theta)
}
}
#function to get the actual cost of the slr initially
costfunction_slr <- function(X, y, theta){
require("ggplot")
#initialise cost to zero value
J = 0
#find the hypothesis
htheta <- X %*% theta
#calculate squared error
sq_error <- (htheta - y)^2
J = J + (1/(2*m))*sum(sq_error)
par(new=TRUE)
plot(y[,1], htheta, 'l', xlab="Population", ylab="Profit")
}
#load the train csv file -- with univariate variable
data1 <- read.csv("ex1data1.txt", check.names = TRUE)
#set the names of the columns of input matrix
names(data1) <- c("Population", "Profit")
#check for classes
classData <- sapply(data1, class)
#retrieve predictor and target variable values
X <- as.matrix(data1[, 1])
y <- as.matrix(data1[, 2])
#plot the data of input and output variables
plot(X[,1], y[,1], 'p', xlab="Population", ylab="Profit")
#add bias to input vector X
X <- cbind(1, X)
#set col names of X and y
colnames(X) <- c("theta0", "Population")
colnames(y) <- c("Profit")
#set row names of X and y
rownames(X) <- as.integer(1:nrow(X))
rownames(y) <- as.integer(1:nrow(y))
#define parameters
alpha = 0.1
iterations = 1500
m <- nrow(X)
theta = matrix(data= 0, nrow = ncol(X), ncol = 1)
calculateGradients(X, y, theta, alpha, iterations)
calculateGradients_slr(X, y, theta, alpha, iterations)
debug(calculateGradients_slr)
calculateGradients_slr(X, y, theta, alpha, iterations)
dim(J_val)
error
grad_temp
theta
a<-c(0,0)
a
b<-matrix(data=2, nrow=2, ncol=1)
b
b %*% t(a)
b <- t(a)
b
#load the train csv file -- with univariate variable
data1 <- read.csv("ex1data1.txt", check.names = TRUE)
#set the names of the columns of input matrix
names(data1) <- c("Population", "Profit")
#check for classes
classData <- sapply(data1, class)
#retrieve predictor and target variable values
X <- as.matrix(data1[, 1])
y <- as.matrix(data1[, 2])
#plot the data of input and output variables
plot(X[,1], y[,1], 'p', xlab="Population", ylab="Profit")
#add bias to input vector X
X <- cbind(1, X)
#set col names of X and y
colnames(X) <- c("theta0", "Population")
colnames(y) <- c("Profit")
#set row names of X and y
rownames(X) <- as.integer(1:nrow(X))
rownames(y) <- as.integer(1:nrow(y))
#define parameters
alpha = 0.1
iterations = 1500
m <- nrow(X)
theta = matrix(data= 0, nrow = ncol(X), ncol = 1)
#calculate the initiall cost without gradient descent
#costvalue <- costfunction_slr(X, y , theta)
#calculate the gradients
calculateGradients_slr(X, y, theta, alpha, iterations)
#plot htheta(decision boundary) over input points to
#check for error graphically
#function to calculate gradients
calculateGradients_slr <- function(X, y, theta, alpha, iterations){
#initialize the gradient matrix
J_val <- matrix(nrow=iterations, ncol=1, data=0)
for (iter in iterations){
htheta <- X %*% theta
error <- (htheta - y)
grad_temp <- rep(0, times=ncol(grad))
for (j in ncol(theta)){
grad_temp[j] <- grad[, j] - (alpha/m) %*% ((error) %*% X[, j])
}
#after calculating current gradient descent for all the parameters
theta <- t(grad_temp)
#get the cost using current theta parameter
J[iter,] <- costfunction_slr(X, y, t(theta))
}
}
#function to get the actual cost of the slr initially
costfunction_slr <- function(X, y, theta){
require("ggplot")
#initialise cost to zero value
J = 0
#find the hypothesis
htheta <- X %*% theta
#calculate squared error
sq_error <- (htheta - y)^2
J = J + (1/(2*m))*sum(sq_error)
par(new=TRUE)
plot(y[,1], htheta, 'l', xlab="Population", ylab="Profit")
}
#function to calculate gradients
calculateGradients_slr <- function(X, y, theta, alpha, iterations){
#initialize the gradient matrix
J_val <- matrix(nrow=iterations, ncol=1, data=0)
for (iter in iterations){
htheta <- X %*% theta
error <- (htheta - y)
grad_temp <- matrix(data=0, nrow=nrow(theta), ncol=1)
for (j in ncol(theta)){
grad_temp[j] <- grad[, j] - (alpha/m) %*% ((error) %*% X[, j])
}
#after calculating current gradient descent for all the parameters
theta <- grad_temp
#get the cost using current theta parameter
J[iter,] <- costfunction_slr(X, y, theta)
}
}
#function to get the actual cost of the slr initially
costfunction_slr <- function(X, y, theta){
require("ggplot")
#initialise cost to zero value
J = 0
#find the hypothesis
htheta <- X %*% theta
#calculate squared error
sq_error <- (htheta - y)^2
J = J + (1/(2*m))*sum(sq_error)
par(new=TRUE)
plot(y[,1], htheta, 'l', xlab="Population", ylab="Profit")
}
calculateGradients_slr(X, y, theta, alpha, iterations)
debug(calculateGradients_slr)
calculateGradients_slr(X, y, theta, alpha, iterations)
dim(htheta)
dim(error)
dim(grad_temp)
#function to calculate gradients
calculateGradients_slr <- function(X, y, theta, alpha, iterations){
#initialize the gradient matrix
J_val <- matrix(nrow=iterations, ncol=1, data=0)
for (iter in iterations){
htheta <- X %*% theta
error <- (htheta - y)
grad_temp <- matrix(data=0, nrow=nrow(theta), ncol=1)
for (j in ncol(theta)){
grad_temp[j] <- grad[, j] - (alpha/m) %*% (t(error) %*% X[, j])
}
#after calculating current gradient descent for all the parameters
theta <- grad_temp
#get the cost using current theta parameter
J[iter,] <- costfunction_slr(X, y, theta)
}
}
debug(calculateGradients_slr)
calculateGradients_slr(X, y, theta, alpha, iterations)
theta
#calculate the gradients
calculateGradients_slr(X, y, theta, alpha, iterations)
#plot htheta(decision boundary) over input points to
#check for error graphically
#function to calculate gradients
calculateGradients_slr <- function(X, y, theta, alpha, iterations){
#initialize the gradient matrix
J_val <- matrix(nrow=iterations, ncol=1, data=0)
for (iter in iterations){
htheta <- X %*% theta
error <- (htheta - y)
grad_temp <- matrix(data=0, nrow=nrow(theta), ncol=1)
for (j in ncol(theta)){
grad_temp[j] <- grad[, j] - (alpha/m) %*% (t(error) %*% X[, j])
}
#after calculating current gradient descent for all the parameters
theta <- grad_temp
#get the cost using current theta parameter
J_val[iter,] <- costfunction_slr(X, y, theta)
}
}
#calculate the gradients
calculateGradients_slr(X, y, theta, alpha, iterations)
#plot htheta(decision boundary) over input points to
#check for error graphically
#function to calculate gradients
calculateGradients_slr <- function(X, y, theta, alpha, iterations){
#initialize the gradient matrix
J_val <- matrix(nrow=iterations, ncol=1, data=0)
for (iter in iterations){
htheta <- X %*% theta
error <- (htheta - y)
grad_temp <- matrix(data=0, nrow=nrow(theta), ncol=1)
for (j in ncol(theta)){
grad_temp[j] <- grad[, j] - (alpha/m) %*% (t(error) %*% X[, j])
}
#after calculating current gradient descent for all the parameters
theta <- grad_temp
#get the cost using current theta parameter
J_val[iter,] <- costfunction_slr(X, y, theta)
}
}
#function to calculate gradients
calculateGradients_slr <- function(X, y, theta, alpha, iterations){
#initialize the gradient matrix
J_val <- matrix(nrow=iterations, ncol=1, data=0)
for (iter in iterations){
htheta <- X %*% theta
error <- (htheta - y)
grad_temp <- matrix(data=0, nrow=nrow(theta), ncol=1)
for (j in ncol(theta)){
grad_temp[j] <- grad[, j] - (alpha/m) %*% (t(error) %*% X[, j])
}
#after calculating current gradient descent for all the parameters
theta <- grad_temp
#get the cost using current theta parameter
J_val[iter,] <- costfunction_slr(X, y, theta)
}
}
#function to calculate gradients
calculateGradients_slr <- function(X, y, theta, alpha, iterations){
#initialize the gradient matrix
J_val <- matrix(nrow=iterations, ncol=1, data=0)
for (iter in iterations){
htheta <- X %*% theta
error <- (htheta - y)
grad_temp <- matrix(data=0, nrow=nrow(theta), ncol=1)
for (j in ncol(theta)){
grad_temp[j] <- grad[, j] - (alpha/m) %*% (t(error) %*% X[, j])
}
#after calculating current gradient descent for all the parameters
theta <- grad_temp
#get the cost using current theta parameter
J_val[iter,] <- costfunction_slr(X, y, theta)
}
return (J_val)
}
J_iterations <- calculateGradients_slr(X, y, theta, alpha, iterations)
#function to calculate gradients
calculateGradients_slr <- function(X, y, theta, alpha, iterations){
#initialize the gradient matrix
J_val <- matrix(nrow=iterations, ncol=1, data=0)
for (iter in iterations){
htheta <- X %*% theta
error <- (htheta - y)
grad_temp <- matrix(data=0, nrow=nrow(theta), ncol=1)
for (j in ncol(theta)){
grad_temp[j, ] <- grad[, j] - (alpha/m) %*% (t(error) %*% X[, j])
}
#after calculating current gradient descent for all the parameters
theta <- grad_temp
#get the cost using current theta parameter
J_val[iter,] <- costfunction_slr(X, y, theta)
}
return (J_val)
}
J_iterations <- calculateGradients_slr(X, y, theta, alpha, iterations)
X[,1]
#function to calculate gradients
calculateGradients_slr <- function(X, y, theta, alpha, iterations){
#initialize the gradient matrix
J_val <- matrix(nrow=iterations, ncol=1, data=0)
for (iter in iterations){
htheta <- X %*% theta
error <- (htheta - y)
grad_temp <- matrix(data=0, nrow=nrow(theta), ncol=1)
for (j in ncol(theta)){
grad_temp[j, ] <- grad[, j] - (alpha/m) %*% sum(t(error) %*% X[, j])
}
#after calculating current gradient descent for all the parameters
theta <- grad_temp
#get the cost using current theta parameter
J_val[iter,] <- costfunction_slr(X, y, theta)
}
return (J_val)
}
J_iterations <- calculateGradients_slr(X, y, theta, alpha, iterations)
#plot htheta(decision boundary) over input points to
#check for error graphically
#function to calculate gradients
calculateGradients_slr <- function(X, y, theta, alpha, iterations){
#initialize the gradient matrix
J_val <- matrix(nrow=iterations, ncol=1, data=0)
for (iter in iterations){
htheta <- X %*% theta
error <- (htheta - y)
grad_temp <- matrix(data=0, nrow=nrow(theta), ncol=1)
for (j in ncol(theta)){
grad_temp[j, ] <- theta[j,] - (alpha/m) %*% sum(t(error) %*% X[, j])
}
#after calculating current gradient descent for all the parameters
theta <- grad_temp
#get the cost using current theta parameter
J_val[iter,] <- costfunction_slr(X, y, theta)
}
return (J_val)
}
J_iterations <- calculateGradients_slr(X, y, theta, alpha, iterations)
#function to calculate gradients
calculateGradients_slr <- function(X, y, theta, alpha, iterations){
#initialize the gradient matrix
J_val <- matrix(nrow=iterations, ncol=1, data=0)
for (iter in iterations){
htheta <- X %*% theta
error <- (htheta - y)
grad_temp <- matrix(data=0, nrow=nrow(theta), ncol=1)
for (j in ncol(theta)){
grad_temp[j, ] <- theta[j,] - (alpha/m) %*% sum(t(error) %*% X[, j])
}
#after calculating current gradient descent for all the parameters
theta <- grad_temp
#get the cost using current theta parameter
J_val[iter,] <- costfunction_slr(X, y, theta)
}
return (J_val)
}
J_iterations <- calculateGradients_slr(X, y, theta, alpha, iterations)
library("ggplot")
library("ggplot2")
